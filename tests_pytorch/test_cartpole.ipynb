{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laurent LEQUIEVRE\n",
    "# Research Engineer, CNRS (France)\n",
    "# Institut Pascal UMR6602\n",
    "# laurent.lequievre@uca.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole : A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cartpole.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 'step' function returns four values :\n",
    "\n",
    "- observation (object): \n",
    "an environment-specific object representing your observation of the environment. \n",
    "For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "\n",
    "- reward (float): \n",
    "amount of reward achieved by the previous action. \n",
    "The scale varies between environments, but the goal is always to increase your total reward.\n",
    "\n",
    "- done (boolean): \n",
    "whether it’s time to reset the environment again. \n",
    "Most (but not all) tasks are divided up into well-defined episodes, and done being True indicates the episode has terminated. \n",
    "(For example, perhaps the pole tipped too far, or you lost your last life.)\n",
    "\n",
    "- info (dict): \n",
    "diagnostic information useful for debugging. \n",
    "It can sometimes be useful for learning (for example, it might contain the raw probabilities behind the environment’s last state change). \n",
    "However, official evaluations of your agent are not allowed to use this for learning.\n",
    "\n",
    "\n",
    "Example for CartPole : array([-0.00842369, -0.17244261, -0.0034994 ,  0.24360119]), 1.0, False, {}\n",
    "    \n",
    "    observation = array([x position of cart, x velocity of cart, angular position of pole, angular velocity of pole])\n",
    "    reward = 1.0\n",
    "    done = False\n",
    "    info = {}\n",
    "    \n",
    "# The 'reset' function returns :\n",
    "\n",
    "- observation (object): \n",
    "an environment-specific object representing your observation of the environment. \n",
    "For example, pixel data from a camera, joint angles and joint velocities of a robot, or the board state in a board game.\n",
    "\n",
    "\n",
    "# About 'done' :\n",
    "\n",
    "- The environment will return done=True if either 200 timesteps have elapsed (episode success) \n",
    "or if the pole has fallen over (angular position of the pole has reached +- 12 degrees) \n",
    "or the cart has left the simulation space (cart position has reached +- 2.4), in which case the episode failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03751017, -0.01408691,  0.01957232, -0.04018988])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')  # CartPole-v0 only runs for 200 steps. CartPole-v1 runs for 500 steps.\n",
    "env.reset() # reset the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment comes with an action_space and an observation_space :\n",
    "\n",
    "These attributes are of type Space, and they describe the format of valid actions and observations.\n",
    "\n",
    "The 'Discrete' space allows a fixed range of non-negative numbers.\n",
    "- Discrete(2) -> in this case valid actions are either 0 or 1.\n",
    "- Discrete(8) -> Set with 8 elements {0, 1, 2, ..., 7}\n",
    "\n",
    "The 'Box' space represents an n-dimensional box.\n",
    "- Box(4,) -> valid observations will be an array of 4 numbers (in that example, there is only one dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space = Discrete(2)\n",
      "nb actions = 2\n",
      "a sample of action = 1\n",
      "a sample of action = 1\n",
      "a sample of action = 0\n",
      "observation space = Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
      "observation high = [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "observation low = [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "x cart pos high = 4.800000190734863\n",
      "x cart pos low = -4.800000190734863\n",
      "x cart velocity high = 3.4028234663852886e+38\n",
      "x cart velocity low = -3.4028234663852886e+38\n",
      "Angular pole pos high = 0.41887903213500977\n",
      "Angular pole pos low = -0.41887903213500977\n",
      "Angular pole velocity high = 3.4028234663852886e+38\n",
      "Angular pole velocity low = -3.4028234663852886e+38\n"
     ]
    }
   ],
   "source": [
    "# About action and observation space\n",
    "\n",
    "# action_space\n",
    "print(\"action space = {}\".format(env.action_space)) # Discrete(2)\n",
    "print(\"nb actions = {}\".format(env.action_space.n)) # 2\n",
    "\n",
    "for _ in range(3):\n",
    "    print(\"a sample of action = {}\".format(env.action_space.sample())) # Randomly sample an element of this space == random(2)\n",
    "\n",
    "# observation_space\n",
    "print(\"observation space = {}\".format(env.observation_space))\n",
    "# observation = x position of cart, x velocity of cart, angular position of pole, angular velocity of pole\n",
    "\n",
    "# We can also check the Box’s bounds\n",
    "print(\"observation high = {}\".format(env.observation_space.high))\n",
    "print(\"observation low = {}\".format(env.observation_space.low))\n",
    "\n",
    "# In details\n",
    "print(\"x cart pos high = {}\".format(env.observation_space.high[0]))\n",
    "print(\"x cart pos low = {}\".format(env.observation_space.low[0]))\n",
    "\n",
    "print(\"x cart velocity high = {}\".format(env.observation_space.high[1]))\n",
    "print(\"x cart velocity low = {}\".format(env.observation_space.low[1]))\n",
    "\n",
    "print(\"Angular pole pos high = {}\".format(env.observation_space.high[2]))\n",
    "print(\"Angular pole pos low = {}\".format(env.observation_space.low[2]))\n",
    "\n",
    "print(\"Angular pole velocity high = {}\".format(env.observation_space.high[3]))\n",
    "print(\"Angular pole velocity low = {}\".format(env.observation_space.low[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple loop to play with the cartPole environment\n",
    "for i in range(100):\n",
    "    env.render() # will open a GUI window and show you the cartpole.\n",
    "    v = env.step(env.action_space.sample()) # apply a random action to the environment\n",
    "env.close() # close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve_pytorch",
   "language": "python",
   "name": "ve_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
