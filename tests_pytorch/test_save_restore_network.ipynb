{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laurent LEQUIEVRE\n",
    "# Research Engineer, CNRS (France)\n",
    "# Institut Pascal UMR6602\n",
    "# laurent.lequievre@uca.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1f7c3e5210>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1) # init random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.unsqueeze(torch.linspace(-1, 1, 10), dim=1)  # x data (tensor), shape=(100, 1)\n",
    "x.requires_grad=False # No gradient\n",
    "\n",
    "y = x.pow(2) + 0.2*torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)\n",
    "y.requires_grad=False # No gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple network\n",
    "net = nn.Sequential(\n",
    "        nn.Linear(1, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 1)\n",
    "    )\n",
    "# use SGD as optimizer (Stochastic Gradient Descent)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# use MSE as loss function (Mean Square Error)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.019857022911310196\n",
      "loss = 0.01944645866751671\n",
      "loss = 0.019048035144805908\n",
      "loss = 0.01866154558956623\n",
      "loss = 0.018286803737282753\n",
      "loss = 0.01792355813086033\n",
      "loss = 0.01757161319255829\n",
      "loss = 0.017230728641152382\n",
      "loss = 0.016900697723031044\n",
      "loss = 0.016581255942583084\n",
      "loss = 0.016272205859422684\n",
      "loss = 0.015973294153809547\n",
      "loss = 0.01568428799510002\n",
      "loss = 0.015404951758682728\n",
      "loss = 0.015135057270526886\n",
      "loss = 0.014874359592795372\n",
      "loss = 0.014622626826167107\n",
      "loss = 0.014379629865288734\n",
      "loss = 0.014145131222903728\n",
      "loss = 0.01391889713704586\n",
      "loss = 0.013700691983103752\n",
      "loss = 0.013490304350852966\n",
      "loss = 0.013287490233778954\n",
      "loss = 0.013092041015625\n",
      "loss = 0.012903735041618347\n",
      "loss = 0.01272234134376049\n",
      "loss = 0.012547662481665611\n",
      "loss = 0.01237948052585125\n",
      "loss = 0.012217596173286438\n",
      "loss = 0.012061788700520992\n",
      "loss = 0.011911881156265736\n",
      "loss = 0.011767658405005932\n",
      "loss = 0.011628950014710426\n",
      "loss = 0.011495550163090229\n",
      "loss = 0.011367284692823887\n",
      "loss = 0.011243972927331924\n",
      "loss = 0.011125442571938038\n",
      "loss = 0.011011515744030476\n",
      "loss = 0.010902044363319874\n",
      "loss = 0.010796843096613884\n",
      "loss = 0.010695775970816612\n",
      "loss = 0.010598680935800076\n",
      "loss = 0.010505410842597485\n",
      "loss = 0.010415812954306602\n",
      "loss = 0.01032976619899273\n",
      "loss = 0.0102471224963665\n",
      "loss = 0.010167750529944897\n",
      "loss = 0.010091524571180344\n",
      "loss = 0.010018321685492992\n",
      "loss = 0.009948027320206165\n",
      "loss = 0.009880510158836842\n",
      "loss = 0.009815678000450134\n",
      "loss = 0.00975340511649847\n",
      "loss = 0.009693609550595284\n",
      "loss = 0.009636165574193\n",
      "loss = 0.00958099402487278\n",
      "loss = 0.00952799804508686\n",
      "loss = 0.009477082639932632\n",
      "loss = 0.00942816399037838\n",
      "loss = 0.00938116293400526\n",
      "loss = 0.009335992857813835\n",
      "loss = 0.00929257832467556\n",
      "loss = 0.009250839240849018\n",
      "loss = 0.009210711345076561\n",
      "loss = 0.009172126650810242\n",
      "loss = 0.009135018102824688\n",
      "loss = 0.009099314920604229\n",
      "loss = 0.009064959362149239\n",
      "loss = 0.009031900204718113\n",
      "loss = 0.009000079706311226\n",
      "loss = 0.008969433605670929\n",
      "loss = 0.008939921855926514\n",
      "loss = 0.00891148578375578\n",
      "loss = 0.008884084410965443\n",
      "loss = 0.0088576665148139\n",
      "loss = 0.008832192048430443\n",
      "loss = 0.00880762655287981\n",
      "loss = 0.008783919736742973\n",
      "loss = 0.008761035278439522\n",
      "loss = 0.008738942444324493\n",
      "loss = 0.008717594668269157\n",
      "loss = 0.008696968667209148\n",
      "loss = 0.008677029982209206\n",
      "loss = 0.008657748810946941\n",
      "loss = 0.008639095351099968\n",
      "loss = 0.008621030487120152\n",
      "loss = 0.008603548631072044\n",
      "loss = 0.008586612530052662\n",
      "loss = 0.008570198900997639\n",
      "loss = 0.008554277941584587\n",
      "loss = 0.008538839407265186\n",
      "loss = 0.008523857221007347\n",
      "loss = 0.008509313687682152\n",
      "loss = 0.008495182730257511\n",
      "loss = 0.008481452241539955\n",
      "loss = 0.00846809335052967\n",
      "loss = 0.008455106057226658\n",
      "loss = 0.008442467078566551\n",
      "loss = 0.008430153131484985\n",
      "loss = 0.008418165147304535\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "for t in range(100):\n",
    "        prediction = net(x)\n",
    "        loss = loss_func(prediction, y)\n",
    "        print(\"loss = {}\".format(loss))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'net.pkl')  # save entire net in a file named 'net.pkl' (saved in the current dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_params.pkl')   # save only the parameters in a file named 'net_params.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([[-1.0000],\n",
      "        [-0.7778],\n",
      "        [-0.5556],\n",
      "        [-0.3333],\n",
      "        [-0.1111],\n",
      "        [ 0.1111],\n",
      "        [ 0.3333],\n",
      "        [ 0.5556],\n",
      "        [ 0.7778],\n",
      "        [ 1.0000]])\n",
      "y= tensor([[1.1515],\n",
      "        [0.6608],\n",
      "        [0.3893],\n",
      "        [0.2580],\n",
      "        [0.0182],\n",
      "        [0.1723],\n",
      "        [0.1905],\n",
      "        [0.4595],\n",
      "        [0.7188],\n",
      "        [1.0878]])\n",
      "prediction= tensor([[ 1.0575],\n",
      "        [ 0.7602],\n",
      "        [ 0.4630],\n",
      "        [ 0.1657],\n",
      "        [-0.0326],\n",
      "        [ 0.1299],\n",
      "        [ 0.3349],\n",
      "        [ 0.5399],\n",
      "        [ 0.7449],\n",
      "        [ 0.9499]], grad_fn=<AddmmBackward>)\n",
      "loss = 0.008406473323702812\n"
     ]
    }
   ],
   "source": [
    "# restore entire net to net2\n",
    "net2 = torch.load('net.pkl')\n",
    "prediction = net2(x)\n",
    "\n",
    "print(\"x= {}\".format(x))\n",
    "print(\"y= {}\".format(y))\n",
    "print(\"prediction= {}\".format(prediction))\n",
    "\n",
    "loss = loss_func(prediction, y)\n",
    "print(\"loss = {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([[-1.0000],\n",
      "        [-0.7778],\n",
      "        [-0.5556],\n",
      "        [-0.3333],\n",
      "        [-0.1111],\n",
      "        [ 0.1111],\n",
      "        [ 0.3333],\n",
      "        [ 0.5556],\n",
      "        [ 0.7778],\n",
      "        [ 1.0000]])\n",
      "y= tensor([[1.1515],\n",
      "        [0.6608],\n",
      "        [0.3893],\n",
      "        [0.2580],\n",
      "        [0.0182],\n",
      "        [0.1723],\n",
      "        [0.1905],\n",
      "        [0.4595],\n",
      "        [0.7188],\n",
      "        [1.0878]])\n",
      "prediction= tensor([[ 1.0575],\n",
      "        [ 0.7602],\n",
      "        [ 0.4630],\n",
      "        [ 0.1657],\n",
      "        [-0.0326],\n",
      "        [ 0.1299],\n",
      "        [ 0.3349],\n",
      "        [ 0.5399],\n",
      "        [ 0.7449],\n",
      "        [ 0.9499]], grad_fn=<AddmmBackward>)\n",
      "loss = 0.008406473323702812\n"
     ]
    }
   ],
   "source": [
    "# restore only the parameters of net to net3\n",
    "net3 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 10),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "# copy net's parameters into net3\n",
    "net3.load_state_dict(torch.load('net_params.pkl'))\n",
    "prediction = net3(x)\n",
    "\n",
    "print(\"x= {}\".format(x))\n",
    "print(\"y= {}\".format(y))\n",
    "print(\"prediction= {}\".format(prediction))\n",
    "\n",
    "loss = loss_func(prediction, y)\n",
    "print(\"loss = {}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve_pytorch",
   "language": "python",
   "name": "ve_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
