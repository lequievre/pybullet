{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laurent LEQUIEVRE\n",
    "# Research Engineer, CNRS (France)\n",
    "# Institut Pascal UMR6602\n",
    "# laurent.lequievre@uca.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Math equation in Jupyter Notebook\n",
    "# https://medium.com/analytics-vidhya/writing-math-equations-in-jupyter-notebook-a-naive-introduction-a5ce87b9a214"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=2.0<br>\n",
    "b=3.0<br>\n",
    "c=a * b<br>\n",
    "$\\partial{c} / \\partial{a} = 3.0$<br>\n",
    "$\\partial{c} / \\partial{b} = 2.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = 6.0\n",
      "a gradient = 3.0, b gradient = 2.0\n"
     ]
    }
   ],
   "source": [
    "# JUST TO REMIND\n",
    "\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "c = a * b\n",
    "print(\"c = {}\".format(c))\n",
    "\n",
    "c.backward() # computes gradient for a and b (which has requires_grad=True)\n",
    "\n",
    "print(\"a gradient = {}, b gradient = {}\".format(a.grad, b.grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad of x = True\n",
      "requires_grad of x ** 2 = True\n",
      "requires_grad of x ** 2 = False\n",
      "requires_grad of x ** 2 = True\n"
     ]
    }
   ],
   "source": [
    "# The wrapper \"with torch.no_grad()\" temporarily set all the requires_grad flag to false inside its context\n",
    "# CLASS torch.no_grad -> Context-manager that disabled gradient calculation.\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(\"requires_grad of x = {}\".format(x.requires_grad)) # True\n",
    "print(\"requires_grad of x ** 2 = {}\".format((x ** 2).requires_grad)) # True\n",
    "\n",
    "# the \"required_grad\" flag of x is temporarily removed\n",
    "# Only in the context of with !\n",
    "with torch.no_grad():\n",
    "    print(\"requires_grad of x ** 2 = {}\".format((x ** 2).requires_grad)) \n",
    "    \n",
    "    \n",
    "# Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). \n",
    "# It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
    "# In this mode, the result of every computation will have requires_grad=False, even when the inputs have requires_grad=True.\n",
    "   \n",
    "print(\"requires_grad of x ** 2 = {}\".format((x ** 2).requires_grad)) # outside of \"with context\" -> True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad of x = True\n",
      "requires_grad of x ** 2 = False\n",
      "requires_grad of x = True\n",
      "requires_grad of x ** 2 = True\n"
     ]
    }
   ],
   "source": [
    "# The same by using a global function : torch.set_grad_enabled\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(\"requires_grad of x = {}\".format(x.requires_grad)) # True\n",
    "print(\"requires_grad of x ** 2 = {}\".format((x ** 2).requires_grad)) # False\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "print(\"requires_grad of x = {}\".format(x.requires_grad)) # True\n",
    "print(\"requires_grad of x ** 2 = {}\".format((x ** 2).requires_grad)) # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4254, -0.3676, -0.1272],\n",
      "        [ 0.1513,  0.5523, -0.2397]])\n",
      "tensor(0.5523)\n"
     ]
    }
   ],
   "source": [
    "# torch.max\n",
    "# The default behavior is to return a single element and an index, corresponding to the global maximum element.\n",
    "\n",
    "p = torch.randn([2, 3])\n",
    "print(p)\n",
    "\n",
    "max_element = torch.max(p)\n",
    "print(max_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5627, -0.0416, -0.7279],\n",
      "        [ 0.7327,  0.7118, -0.3424]])\n",
      "by column max elem = tensor([ 0.7327,  0.7118, -0.3424]), size = torch.Size([3])\n",
      "by column index of max elem = tensor([1, 1, 1])\n",
      "-----------------------------------------\n",
      "by row max elem = tensor([0.5627, 0.7327]), size = torch.Size([2])\n",
      "by row index of max elem = tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Use torch.max() along a dimension\n",
    "# This returns a tuple, max_elements and max_indices.\n",
    "\n",
    "# max_elements, max_indices = torch.max(input_tensor, dim)\n",
    "# max_elements -> All the maximum elements of the Tensor.\n",
    "# max_indices -> Indices corresponding to the maximum elements.\n",
    "\n",
    "p = torch.randn([2, 3])\n",
    "print(p)\n",
    " \n",
    "# Get the maximum along dim = 0 (axis = 0) - Column\n",
    "max_elements, max_idxs = torch.max(p, dim=0)\n",
    "print(\"by column max elem = {}, size = {}\".format(max_elements, max_elements.size()))\n",
    "print(\"by column index of max elem = {}\".format(max_idxs))\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Get the maximum along dim = 1 (axis = 1) - row\n",
    "max_elements, max_idxs = torch.max(p, dim=1)\n",
    "print(\"by row max elem = {}, size = {}\".format(max_elements, max_elements.size()))\n",
    "print(\"by row index of max elem = {}\".format(max_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve_pytorch",
   "language": "python",
   "name": "ve_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
